# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_pp.ipynb.

# %% auto 0
__all__ = ['get_filtered_data', 'create_plot']

# %% ../nbs/02_pp.ipynb 3
import json, os, inspect
import itertools as it
from collections import defaultdict

import numpy as np
import pandas as pd
import datetime as dt

from typing import List, Tuple, Dict, Union, Optional

import altair as alt

from salk_toolkit.plots import *
from salk_toolkit.utils import *
from salk_toolkit.io import load_parquet_with_metadata, extract_column_meta, group_columns_dict, list_aliases

# %% ../nbs/02_pp.ipynb 6
# Augment each draw with bootstrap data from across whole population to make sure there are at least <threshold> samples
def augment_draws(data, factors=None, n_draws=None, threshold=50):
    if n_draws == None: n_draws = data.draw.max()+1
    
    if factors: # Run recursively on each factor separately and concatenate results
        if data[ ['draw']+factors ].value_counts().min() >= threshold: return data # This takes care of large datasets fast
        return data.groupby(factors).apply(augment_draws,n_draws=n_draws,threshold=threshold).reset_index(drop=True) # Slow-ish, but only needed on small data now
    
    # Get count of values for each draw
    draw_counts = data['draw'].value_counts() # Get value counts of existing draws
    if len(draw_counts)<n_draws: # Fill in completely missing draws
        draw_counts = (draw_counts + pd.Series(0,index=range(n_draws))).fillna(0).astype(int)
        
    # If no new draws needed, just return original
    if draw_counts.min()>=threshold: return data
    
    # Generate an index for new draws
    new_draws = [ d for d,c in draw_counts[draw_counts<threshold].items() for _ in range(threshold-c) ]

    # Generate new draws
    new_rows = data.iloc[np.random.choice(len(data),len(new_draws)),:].copy()
    new_rows['draw'] = new_draws
    
    return pd.concat([data, new_rows])

# %% ../nbs/02_pp.ipynb 7
# Get all data required for a given graph
# Only return columns and rows that are needed
# This is self-contained so it can be moved to polars later
def get_filtered_data(full_df, data_meta, columns=None, **kwargs):
    
    # Figure out which columns we actually need
    meta_cols = ['draw', 'weight']
    cols = [ kwargs['res_col'] ]  + vod(kwargs,'factor_cols',[]) + list(vod(kwargs,'filter',{}).keys()) + [ c for c in meta_cols if c in full_df.columns ]
    
    # If any aliases are used, cconvert them to column names according to the data_meta
    gc_dict = group_columns_dict(data_meta)
    cols = [ c for c in list_aliases(cols,gc_dict) if c in full_df.columns ]
    
    df = full_df[cols]
    
    # If res_col is a group of questions
    # This might move to wrangle but currently easier to do here as we have gc_dict handy
    if kwargs['res_col'] in gc_dict:
        value_vars = [ c for c in gc_dict[kwargs['res_col']] if c in cols ]
        id_vars = [ c for c in cols if c not in value_vars ]
        df = df.melt(id_vars=id_vars, value_vars=value_vars, var_name='question', value_name=kwargs['res_col'])
        df['question'] = pd.Categorical(df['question'],gc_dict[kwargs['res_col']])
    
    # Filter using demographics dict. This is very clever but hard to read. See:
    # https://stackoverflow.com/questions/34157811/filter-a-pandas-dataframe-using-values-from-a-dict
    filter_dict = vod(kwargs,'filter',{})
    filtered_df = df[(df[list(filter_dict)] == pd.Series(filter_dict,dtype='str')).all(axis=1)]
    
    return filtered_df

# %% ../nbs/02_pp.ipynb 9
# Groupby if needed - this simplifies the wrangle considerably :)
def gb_in(df, gb_cols):
    return df.groupby(gb_cols) if len(gb_cols)>0 else df

# Helper function that handles reformating data for create_plot
def wrangle_data(raw_df, res_col, factor_cols, draws=False, continuous=False, data_format='longform',**kwargs):
    gb_dims = (['draw'] if draws else []) + (factor_cols if factor_cols else []) + (['question'] if 'question' in raw_df.columns else [])
    
    if 'weight' not in raw_df.columns and not continuous: raw_df['weight'] = 1
    
    if draws: 
        if 'draw' in raw_df.columns: # Draw present in data
            raw_df = augment_draws(raw_df,gb_dims[1:],threshold=50)
        else: # Draw not present - emulate it with a bootstrap
            pass # TODO
    
    rv = { 'value_col': 'value' }
    
    if data_format=='raw':
        rv['value_col'] = res_col
        if vod(kwargs,'sample'):
            rv['data'] = gb_in(raw_df[gb_dims+[res_col]],gb_dims).sample(kwargs['sample'])
        else: rv['data'] = raw_df[gb_dims+[res_col]]

    elif False and data_format=='table': # TODO: Untested. Fix when first needed
        ddf = pd.get_dummies(raw_df[res_col])
        res_cols = list(ddf.columns)
        ddf.loc[:,gb_dims] = raw_df[gb_dims]
        rv['data'] = gb_in(ddf,gb_dims)[res_cols].mean().reset_index()
    elif data_format=='longform':
        if continuous:
            rv['data'] = gb_in(raw_df,gb_dims)[res_col].mean().reset_index() 
            rv['value_col'] = res_col
        else: # categorical
            rv['cat_col'] = res_col 
            rv['value_col'] = 'percent'
            rv['data'] = (raw_df.groupby(gb_dims+[res_col])['weight'].sum()/gb_in(raw_df,gb_dims)['weight'].sum()).rename(rv['value_col']).reset_index()
    else:
        raise Exception("Unknown data_format")
        
    # Ensure all rv columns other than value are categorical
    for c in rv['data'].columns:
        if rv['data'][c].dtype.name != 'categorical' and c!=rv['value_col']:
            rv['data'].loc[:,c] = pd.Categorical(rv['data'][c])
            
    return rv

# %% ../nbs/02_pp.ipynb 11
# Function that takes filtered raw data and plot information and outputs the plot
# Handles all of the data wrangling and parameter formatting
def create_plot(filtered_df, data_meta, plot, alt_properties={}, **kwargs):
    plot_meta = get_plot_meta(plot)
    col_meta = extract_column_meta(data_meta)
    
    params = wrangle_data(filtered_df, **plot_meta, **kwargs)
    if 'plot_args' in kwargs: params.update(kwargs['plot_args'])
    params['color_scale'] = to_alt_scale(vod(col_meta[kwargs['res_col']],'colors'))

    # Handle factor columns 
    factor_cols = vod(kwargs,'factor_cols',[])
    
    # If we have a question column not handled by the plot, add it to factors:
    if 'question' in filtered_df.columns and not vod(plot_meta,'question'):
        factor_cols = factor_cols + ['question']
    # If we don't have a question column but need it, just fill it with res_col name
    elif 'question' not in filtered_df.columns and vod(plot_meta,'question'):
        params['data']['question'] = pd.Categorical([kwargs['res_col']]*len(params['data']))
        
    if vod(plot_meta,'question'):
        params['question_color_scale'] = to_alt_scale(vod(col_meta[kwargs['res_col']],'question_colors'))
    
    if factor_cols:
        # See if we should use it as an internal facet?
        plot_args = vod(kwargs,'plot_args',{})
        if vod(plot_args,'internal_facet'):
            params['factor_col'] = factor_cols[0]
            params['factor_color_scale'] = to_alt_scale(vod(vod(col_meta,kwargs['factor_cols'][0],{}),'colors'))
            factor_cols = factor_cols[1:] # Leave rest for external faceting
        
        # If we still have more than 1 factor - merge the rest
        if len(factor_cols)>1:
            df = params['data']
            factor_col = '+'.join(factor_cols)
            df.loc[:,factor_col] = df[factor_cols].agg(', '.join, axis=1)
            params['data'] = df
            n_facet_cols = len(df[factor_cols[-1]].dtype.categories)
            factor_cols = [factor_col]
        else:
            n_facet_cols = vod(plot_meta,'factor_columns',1)
    
    plot_fn = get_plot_fn(plot)
            
    # Trim down parameters list if needed
    aspec = inspect.getfullargspec(plot_fn)
    if aspec.varkw is None: params = { k:v for k,v in params.items() if k in aspec.args }
    
    # Create the plot using it's function
    plot = plot_fn(**params).properties(**alt_properties)
    
    # Handle rest of factors via altair facet
    if factor_cols:
        n_facet_cols = vod(plot_args,'n_facet_cols',n_facet_cols) # Allow plot_args to override col nr
        plot = plot.facet(f'{factor_cols[0]}:N',columns=n_facet_cols)
    
    return plot
