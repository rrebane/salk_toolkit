{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Pipeline\n",
    "> Pipeline from raw survey data file up to creating the plot\n",
    "> Built around the use of plot registry from plots.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "import json, os, inspect\n",
    "import itertools as it\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "from salk_toolkit.plots import stk_plot, stk_deregister, matching_plots, get_plot_fn, get_plot_meta\n",
    "from salk_toolkit.utils import *\n",
    "from salk_toolkit.io import load_parquet_with_metadata, extract_column_meta, group_columns_dict, list_aliases, read_annotated_data, read_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple args value for testing individual functions\n",
    "args = {\n",
    "    'res_col' : 'party_preference',\n",
    "    'factor_cols': ['EKRE'],\n",
    "    'filter': { 'nationality': 'Estonian', 'EKRE': (-3,2), 'age_group': ('35-44', '75+') },\n",
    "    'plot': 'boxplots',\n",
    "    'plot_args': { 'internal_facet': False }\n",
    "}\n",
    "\n",
    "# Load a basic bootstrapped dataset\n",
    "full_df, f_meta = load_parquet_with_metadata('../../salk_internal_package/samples/bootstrap.parquet')\n",
    "data_meta = f_meta['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read metafile directly - allows faster iteration\n",
    "data_metafile = '../data/master_meta.json'\n",
    "if data_metafile:\n",
    "    from salk_toolkit.utils import replace_constants\n",
    "    data_meta = read_json(data_metafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "# Augment each draw with bootstrap data from across whole population to make sure there are at least <threshold> samples\n",
    "def augment_draws(data, factors=None, n_draws=None, threshold=50):\n",
    "    if n_draws == None: n_draws = data.draw.max()+1\n",
    "    \n",
    "    if factors: # Run recursively on each factor separately and concatenate results\n",
    "        if data[ ['draw']+factors ].value_counts().min() >= threshold: return data # This takes care of large datasets fast\n",
    "        return data.groupby(factors).apply(augment_draws,n_draws=n_draws,threshold=threshold).reset_index(drop=True) # Slow-ish, but only needed on small data now\n",
    "    \n",
    "    # Get count of values for each draw\n",
    "    draw_counts = data['draw'].value_counts() # Get value counts of existing draws\n",
    "    if len(draw_counts)<n_draws: # Fill in completely missing draws\n",
    "        draw_counts = (draw_counts + pd.Series(0,index=range(n_draws))).fillna(0).astype(int)\n",
    "        \n",
    "    # If no new draws needed, just return original\n",
    "    if draw_counts.min()>=threshold: return data\n",
    "    \n",
    "    # Generate an index for new draws\n",
    "    new_draws = [ d for d,c in draw_counts[draw_counts<threshold].items() for _ in range(threshold-c) ]\n",
    "\n",
    "    # Generate new draws\n",
    "    new_rows = data.iloc[np.random.choice(len(data),len(new_draws)),:].copy()\n",
    "    new_rows['draw'] = new_draws\n",
    "    \n",
    "    return pd.concat([data, new_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Get all data required for a given graph\n",
    "# Only return columns and rows that are needed\n",
    "# This is self-contained so it can be moved to polars later\n",
    "def get_filtered_data(full_df, data_meta, columns=None, **kwargs):\n",
    "    \n",
    "    # Figure out which columns we actually need\n",
    "    meta_cols = ['draw', 'weight', 'training_subsample']\n",
    "    cols = [ kwargs['res_col'] ]  + vod(kwargs,'factor_cols',[]) + list(vod(kwargs,'filter',{}).keys()) + [ c for c in meta_cols if c in full_df.columns ]\n",
    "    \n",
    "    # If any aliases are used, cconvert them to column names according to the data_meta\n",
    "    gc_dict = group_columns_dict(data_meta)\n",
    "    cols = [ c for c in np.unique(list_aliases(cols,gc_dict)) if c in full_df.columns ]\n",
    "    \n",
    "    #print(\"C\",cols)\n",
    "    \n",
    "    df = full_df[cols]\n",
    "    \n",
    "    # Filter using demographics dict. This is very clever but hard to read. See:\n",
    "    filter_dict = vod(kwargs,'filter',{})\n",
    "    inds = np.full(len(df),True)\n",
    "    for k, v in filter_dict.items():\n",
    "        if isinstance(v,tuple): # Tuples specify a range\n",
    "            if df[k].dtype.name == 'category': # Add a safety in case category lists do not fully match (f.i. filter is working off a longer list)\n",
    "                cats = df[k].dtype.categories\n",
    "                v0 = v[0] if v[0] in cats else cats[0]\n",
    "                v1 = v[1] if v[1] in cats else cats[-1]\n",
    "            else: v0,v1 = v[0], v[1]\n",
    "            inds = (((df[k]>=v0) & (df[k]<=v1)) | df[k].isna()) & inds\n",
    "        elif isinstance(v,list): # List indicates a set of values\n",
    "            inds = df[k].isin(v) & inds\n",
    "        else: # Just filter on single value\n",
    "            inds = (df[k]==v) & inds\n",
    "        #if not inds.any():\n",
    "        #    print(f\"None left after {k}:{v}\")\n",
    "        #    break\n",
    "    filtered_df = df[inds]\n",
    "    \n",
    "    # If res_col is a group of questions\n",
    "    # This might move to wrangle but currently easier to do here as we have gc_dict handy\n",
    "    if kwargs['res_col'] in gc_dict:\n",
    "        value_vars = [ c for c in gc_dict[kwargs['res_col']] if c in cols ]\n",
    "        id_vars = [ c for c in cols if c not in value_vars ]\n",
    "        filtered_df = filtered_df.melt(id_vars=id_vars, value_vars=value_vars, var_name='question', value_name=kwargs['res_col'])\n",
    "        filtered_df['question'] = pd.Categorical(filtered_df['question'],gc_dict[kwargs['res_col']])\n",
    "        \n",
    "    # If not poststratisfied\n",
    "    if not vod(kwargs,'poststrat'):\n",
    "        filtered_df['weight'] = 1.0 # Remove weighting\n",
    "        if 'training_subsample' in filtered_df.columns:\n",
    "            filtered_df = filtered_df[filtered_df['training_subsample']]\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = get_filtered_data(full_df, data_meta, **args)\n",
    "assert fdf.EKRE.min() == -3 and fdf.EKRE.max() == 2\n",
    "assert fdf.age_group.min() == '35-44'\n",
    "fdf.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "# Groupby if needed - this simplifies the wrangle considerably :)\n",
    "def gb_in(df, gb_cols):\n",
    "    return df.groupby(gb_cols) if len(gb_cols)>0 else df\n",
    "\n",
    "def discretize_continuous(col, col_meta={}):\n",
    "    # NB! qcut might be a better default - see where testing leads us\n",
    "    cut = pd.cut(col, bins = vod(col_meta,'bins',5), labels = vod(col_meta,'bin_labels',None) )\n",
    "    cut = pd.Categorical(cut.astype(str), map(str,cut.dtype.categories), True) # Convert from intervals to strings for it to play nice with altair\n",
    "    return cut\n",
    "\n",
    "# Helper function that handles reformating data for create_plot\n",
    "def wrangle_data(raw_df, plot_meta, col_meta, res_col, factor_cols ,**kwargs):\n",
    "    \n",
    "    draws, continuous, data_format = (vod(plot_meta, n, False) for n in ['draws','continuous','data_format'])\n",
    "    \n",
    "    gb_dims = (['draw'] if draws else []) + (factor_cols if factor_cols else []) + (['question'] if 'question' in raw_df.columns else [])\n",
    "    \n",
    "    if 'weight' not in raw_df.columns: raw_df['weight'] = 1.0\n",
    "    else: raw_df['weight'] = raw_df['weight'].fillna(1.0)\n",
    "    \n",
    "    if draws and 'draw' in raw_df.columns: # Draw present in data\n",
    "        raw_df = augment_draws(raw_df,gb_dims[1:],threshold=50) # Augment draws so we always have 50 data points in each\n",
    "        \n",
    "    rv = { 'value_col': 'value' }\n",
    "    \n",
    "    if data_format=='raw':\n",
    "        rv['value_col'] = res_col\n",
    "        if vod(plot_meta,'sample'):\n",
    "            rv['data'] = gb_in(raw_df[gb_dims+[res_col]],gb_dims).sample(plot_meta['sample'],replace=True)\n",
    "        else: rv['data'] = raw_df[gb_dims+[res_col]]\n",
    "\n",
    "    elif False and data_format=='table': # TODO: Untested. Fix when first needed\n",
    "        ddf = pd.get_dummies(raw_df[res_col])\n",
    "        res_cols = list(ddf.columns)\n",
    "        ddf.loc[:,gb_dims] = raw_df[gb_dims]\n",
    "        rv['data'] = gb_in(ddf,gb_dims)[res_cols].mean().reset_index()\n",
    "        \n",
    "    elif data_format=='longform':\n",
    "        if continuous:\n",
    "            rv['data'] = gb_in(raw_df,gb_dims)[res_col].mean().dropna().reset_index() \n",
    "            rv['value_col'] = res_col\n",
    "        else: # categorical\n",
    "            rv['cat_col'] = res_col \n",
    "            rv['value_col'] = 'percent'\n",
    "            rv['data'] = (raw_df.groupby(gb_dims+[res_col])['weight'].sum()/gb_in(raw_df,gb_dims)['weight'].sum()).rename(rv['value_col']).dropna().reset_index()\n",
    "            \n",
    "    else:\n",
    "        raise Exception(\"Unknown data_format\")\n",
    "        \n",
    "    # Ensure all rv columns other than value are categorical\n",
    "    for c in rv['data'].columns:\n",
    "        if rv['data'][c].dtype.name != 'category' and c!=rv['value_col']:\n",
    "            if vod(vod(col_meta,c,{}),'continuous'):\n",
    "                rv['data'].loc[:,c] = discretize_continuous(rv['data'][c],vod(col_meta,c,{}))\n",
    "            else: # Just assume it's categorical by any other name\n",
    "                rv['data'].loc[:,c] = pd.Categorical(rv['data'][c])\n",
    "            \n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wdf = wrangle_data(fdf, **args, **get_plot_meta(args['plot']))\n",
    "wdf = wrangle_data(fdf, {'continuous':True, 'data_format':'raw'}, {'EKRE':{'continuous':True}}, **args)\n",
    "wdf['data'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "ordered_gradient = [\"#c30d24\", \"#f3a583\", \"#94c6da\", \"#1770ab\"]\n",
    "\n",
    "def meta_color_scale(cmeta,argname='colors',column=None):\n",
    "    scale = vod(cmeta,argname)\n",
    "    cats = column.dtype.categories if column.dtype.name=='category' else None\n",
    "    if scale is None and column is not None and column.dtype.name=='category' and column.dtype.ordered:\n",
    "        scale = dict(zip(cats,gradient_to_discrete_color_scale(ordered_gradient, len(cats))))\n",
    "    return to_alt_scale(scale,cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Function that takes filtered raw data and plot information and outputs the plot\n",
    "# Handles all of the data wrangling and parameter formatting\n",
    "def create_plot(filtered_df, data_meta, plot, alt_properties={}, dry_run=False, width=200, **kwargs):\n",
    "    plot_meta = get_plot_meta(plot)\n",
    "    col_meta = extract_column_meta(data_meta)\n",
    "    col_meta['question'] = vod(col_meta[kwargs['res_col']],'question_colors',{})\n",
    "    \n",
    "    params = wrangle_data(filtered_df, plot_meta, col_meta, **kwargs)\n",
    "    data = params['data']\n",
    "    \n",
    "    if 'plot_args' in kwargs: params.update(kwargs['plot_args'])\n",
    "    params['color_scale'] = meta_color_scale(col_meta[kwargs['res_col']],'colors',data[kwargs['res_col']])\n",
    "    if filtered_df[kwargs['res_col']].dtype.name=='category':\n",
    "        params['cat_order'] = list(filtered_df[kwargs['res_col']].dtype.categories)\n",
    "\n",
    "    # Handle factor columns \n",
    "    factor_cols = vod(kwargs,'factor_cols',[])\n",
    "    \n",
    "    # If we have a question column not handled by the plot, add it to factors:\n",
    "    if 'question' in data.columns and not vod(plot_meta,'question'):\n",
    "        factor_cols = factor_cols + ['question']\n",
    "    # If we don't have a question column but need it, just fill it with res_col name\n",
    "    elif 'question' not in data.columns and vod(plot_meta,'question'):\n",
    "        data.loc[:,'question'] = pd.Categorical([kwargs['res_col']]*len(params['data']))\n",
    "        \n",
    "    if vod(plot_meta,'question'):\n",
    "        params['question_color_scale'] = meta_color_scale(col_meta[kwargs['res_col']],'question_colors',filtered_df['question'])\n",
    "        params['question_order'] = list(filtered_df['question'].dtype.categories)\n",
    "    \n",
    "    if factor_cols:\n",
    "        # See if we should use it as an internal facet?\n",
    "        plot_args = vod(kwargs,'plot_args',{})\n",
    "        if vod(kwargs,'internal_facet'):\n",
    "            params['factor_col'] = factor_cols[0]\n",
    "            params['factor_color_scale'] = meta_color_scale(col_meta[factor_cols[0]],'colors',data[factor_cols[0]])\n",
    "            params['factor_order'] = list(data[factor_cols[0]].dtype.categories)\n",
    "            factor_cols = factor_cols[1:] # Leave rest for external faceting\n",
    "        \n",
    "        # If we still have more than 1 factor - merge the rest\n",
    "        if len(factor_cols)>1:\n",
    "            factor_col = '+'.join(factor_cols)\n",
    "            data.loc[:,factor_col] = data[factor_cols].agg(', '.join, axis=1)\n",
    "            params['data'] = data\n",
    "            n_facet_cols = len(data[factor_cols[-1]].dtype.categories)\n",
    "            factor_cols = [factor_col]\n",
    "        else:\n",
    "            n_facet_cols = vod(plot_meta,'factor_columns',1)\n",
    "    \n",
    "    plot_fn = get_plot_fn(plot)\n",
    "            \n",
    "    # Trim down parameters list if needed\n",
    "    aspec = inspect.getfullargspec(plot_fn)\n",
    "    if aspec.varkw is None: params = { k:v for k,v in params.items() if k in aspec.args }\n",
    "    \n",
    "    # Create the plot using it's function\n",
    "    if dry_run: return params\n",
    "\n",
    "    dims = {'width': width//n_facet_cols if factor_cols else width}\n",
    "    if 'aspect_ratio' in plot_meta:   dims['height'] = int(dims['width']/plot_meta['aspect_ratio'])        \n",
    "    plot = plot_fn(**params).properties(**dims, **alt_properties)\n",
    "    \n",
    "    # Handle rest of factors via altair facet\n",
    "    if factor_cols:\n",
    "        n_facet_cols = vod(plot_args,'n_facet_cols',n_facet_cols) # Allow plot_args to override col nr\n",
    "        plot = plot.facet(f'{factor_cols[0]}:O',columns=n_facet_cols)\n",
    "    \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'res_col' : 'thermometer',\n",
    "    'factor_cols': ['party_preference'],\n",
    "    'filter': { 'nationality': 'Estonian' },\n",
    "    'plot': 'boxplots-cont',\n",
    "    'internal_facet': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = get_filtered_data(full_df, data_meta, **args)\n",
    "#wdf = wrangle_data(fdf, **args, **get_plot_meta(args['plot']))\n",
    "#fdf['data'].sample(5)\n",
    "create_plot(fdf,data_meta,width=800,**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# A convenience function to draw a plot straight from a dataset\n",
    "def e2e_plot(pp_desc, data_file=None, full_df=None, data_meta=None, width=800, check_match=True):\n",
    "    if data_file is None and full_df is None:\n",
    "        raise Exception('Data must be provided either as data_file or full_df')\n",
    "    if data_file is None and data_meta is None:\n",
    "        raise Exception('If data provided as full_df then data_meta must also be given')\n",
    "        \n",
    "    if full_df is None: full_df, data_meta = read_annotated_data(data_file)\n",
    "    \n",
    "    matches = matching_plots(pp_desc, full_df, data_meta, details=True)\n",
    "    \n",
    "    if pp_desc['plot'] not in matches: \n",
    "        raise Exception(f\"Plot not registered: {pp_desc['plot']}\")\n",
    "    \n",
    "    fit, imp = matches[pp_desc['plot']]\n",
    "    if  fit<0:\n",
    "        raise Exception(f\"Plot {pp_desc['plot']} not applicable in this situation because of flags {imp}\")\n",
    "        \n",
    "    fdf = get_filtered_data(full_df, data_meta, **pp_desc)\n",
    "    return create_plot(fdf,data_meta,width=width,**pp_desc)\n",
    "\n",
    "# Another convenience function to simplify testing new plots\n",
    "def test_new_plot(fn, pp_desc, *args, plot_meta={}, **kwargs):\n",
    "    stk_plot(**{**plot_meta,'plot_name':'test'})(fn) # Register the plot under name 'test'\n",
    "    pp_desc = {**pp_desc, 'plot': 'test'}\n",
    "    res = e2e_plot(pp_desc,*args,**kwargs)\n",
    "    stk_deregister('test') # And de-register it again\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "# Test test_new_plot\n",
    "def smooth(data, cat_col, value_col='value', color_scale=alt.Undefined, factor_col=None):\n",
    "    options_cols = list(data[cat_col].dtype.categories)\n",
    "    ldict = dict(zip(options_cols, range(len(options_cols))))\n",
    "    data.loc[:,'order'] = data[cat_col].replace(ldict)\n",
    "    plot=alt.Chart(data\n",
    "        ).mark_area(interpolate='natural').encode(\n",
    "            x=alt.X(f'{factor_col}:O', title=None),\n",
    "            y=alt.Y(f'{value_col}:Q', title=None, stack='normalize',\n",
    "                 scale=alt.Scale(domain=[0, 1]), axis=alt.Axis(format='%')\n",
    "                 ),\n",
    "            order=\"order:O\",\n",
    "            color=alt.Color(cat_col, legend=alt.Legend(orient='top', title=None),\n",
    "                sort=alt.SortField(\"order\", \"descending\"), scale=color_scale\n",
    "                )\n",
    "        )\n",
    "    return plot\n",
    "\n",
    "test_new_plot(smooth, {\n",
    "    'res_col' : 'party_preference',\n",
    "    'factor_cols': ['age_group','gender'],  'filter': {},\n",
    "    'plot': 'area_smooth',\n",
    "    'internal_facet': True\n",
    "}, full_df=full_df, data_meta=data_meta, plot_meta={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
