{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dashboard\n",
    "> Modular pieces for streamlit dashboards\n",
    "> All of this is meant to be run in a streamlit environment and is likely to fail elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "import json, os, csv, re\n",
    "import itertools as it\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import datetime as dt\n",
    "\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "\n",
    "import altair as alt\n",
    "import s3fs\n",
    "\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "from salk_toolkit.utils import *\n",
    "from salk_toolkit.io import *\n",
    "from salk_toolkit.pp import e2e_plot\n",
    "\n",
    "import streamlit as st\n",
    "from streamlit_option_menu import option_menu\n",
    "from streamlit_dimensions import st_dimensions\n",
    "import streamlit_authenticator as stauth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_plot_width(key):\n",
    "    wobj = st_dimensions(key=key) or { 'width': 800 }# Can return none so handle that\n",
    "    return min(800,int(0.85*wobj['width'])) # Needs to be adjusted down  to leave margin for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Open either a local or an s3 file\n",
    "def open_fn(fname, *args, s3_fs=None, **kwargs):\n",
    "    if fname[:3] == 's3:':\n",
    "        if s3_fs is None: s3_fs = s3fs.S3FileSystem(anon=False)\n",
    "        return s3_fs.open(fname,*args,**kwargs)\n",
    "    else:\n",
    "        return open(fname,*args,**kwargs)\n",
    "    \n",
    "def exists_fn(fname, *args, s3_fs=None, **kwargs):\n",
    "    if fname[:3] == 's3:':\n",
    "        if s3_fs is None: s3_fs = s3fs.S3FileSystem(anon=False)\n",
    "        return s3_fs.exists(fname,*args,**kwargs)\n",
    "    else:\n",
    "        return os.path.exists(fname,*args,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# ttl=None - never expire. Makes sense for potentially big data files\n",
    "@st.cache_resource(show_spinner=False,ttl=None)\n",
    "def read_annotated_data_cached(data_source,**kwargs):\n",
    "    return read_annotated_data(data_source,**kwargs)\n",
    "\n",
    "# Load json uncached - useful for admin pages\n",
    "def load_json(fname, _s3_fs=None, **kwargs):\n",
    "    with open_fn(fname,'r',s3_fs=_s3_fs,encoding='utf8') as jf:\n",
    "        return json.load(jf)\n",
    "\n",
    "# This is cached very short term (1 minute) to avoid downloading it on every page change\n",
    "# while still allowing users to be added / changed relatively responsively\n",
    "@st.cache_resource(show_spinner=False,ttl=60)\n",
    "def load_json_cached(fname, _s3_fs=None, **kwargs):\n",
    "    return load_json(fname,_s3_fs,**kwargs)\n",
    "\n",
    "# For saving json back \n",
    "def save_json(d, fname, _s3_fs=None, **kwargs):\n",
    "    with open_fn(fname,'w',s3_fs=_s3_fs,encoding='utf8') as jf:\n",
    "        json.dump(d,jf,indent=2,ensure_ascii=False)\n",
    "        \n",
    "def alias_file(fname, file_map):\n",
    "    if fname[:3]!='s3:' and fname in file_map and not os.path.exists(fname):\n",
    "        #print(f\"Redirecting {fname} to {file_map[fname]}\")\n",
    "        return file_map[fname]\n",
    "    else: return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "def log_event(event, username, path, s3_fs=None):\n",
    "    timestamp = dt.datetime.now(dt.timezone.utc).strftime('%d-%m-%Y, %H:%M:%S')\n",
    "    with open_fn(path,'a',s3_fs=s3_fs) as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([timestamp, event, username])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "# wrap the first parameter of streamlit function with self.translate\n",
    "# has to be a separate function instead of in a for loop for scoping reasons\n",
    "def wrap_st_with_translate(fn,self):\n",
    "    func = getattr(st,fn)\n",
    "    setattr(self, fn, lambda s, *args, **kwargs: func(self.tf(s),*args,**kwargs) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Main dashboard wrapper - WIP\n",
    "class SalkDashboardBuilder:\n",
    "\n",
    "    def __init__(self, data_source, auth_conf, logfile, groups=['guest','user','admin'], public=False, translate=None):\n",
    "        \n",
    "        # Allow deployment.json to redirect files from local to s3 if local missing (i.e. in deployment scenario)\n",
    "        if os.path.exists('deployment.json'):\n",
    "            dep_meta = load_json_cached('deployment.json')\n",
    "            self.filemap = vod(dep_meta,'files',{})\n",
    "            data_source = alias_file(data_source,self.filemap)\n",
    "            auth_conf = alias_file(auth_conf,self.filemap)\n",
    "        else: self.filemap = {}\n",
    "        \n",
    "        self.log_path = alias_file(logfile, self.filemap)\n",
    "        self.s3fs = s3fs.S3FileSystem(anon=False) # Initialize s3 access. Key in secrets.toml\n",
    "        self.data_source = data_source\n",
    "        self.public = public\n",
    "        self.pages = []\n",
    "        self.sb_info = st.sidebar.empty()\n",
    "        self.info = st.empty()\n",
    "        \n",
    "        # Set up translation\n",
    "        self.tf = translate if translate else (lambda s: s)\n",
    "        \n",
    "        self.p_widths = {}\n",
    "        \n",
    "        # Set up authentication\n",
    "        with st.spinner(self.tf(\"Setting up authentication...\")):\n",
    "            self.uam = UserAuthenticationManager(auth_conf, groups, s3_fs=self.s3fs, info=self.info, logger=self.log_event, translate_func=self.tf)\n",
    "\n",
    "        if not public:\n",
    "            self.uam.login_screen()\n",
    "            \n",
    "        # Wrap some streamlit functions with translate\n",
    "        wrap_list = ['write','markdown','title','header','subheader','caption','text','divider',\n",
    "                     'button','download_button','link_button','checkbox','toggle','radio','selectbox',\n",
    "                     'multiselect','slider','select_slider','text_input','number_input','text_area',\n",
    "                     'date_input','time_input','file_uploader','camera_input','color_picker']\n",
    "        for fn in wrap_list:\n",
    "            wrap_st_with_translate(fn,self)\n",
    "\n",
    "    @property\n",
    "    def user(self):\n",
    "        return self.uam.user\n",
    "    \n",
    "    def log_event(self, event, username=None):\n",
    "        log_event(event, username or st.session_state['username'], self.log_path, s3_fs=self.s3fs)\n",
    "\n",
    "    # pos_id is for plot_width to work in columns\n",
    "    def plot(self, pp_desc, pos_id='main', **kwargs):\n",
    "        # Find or reuse width\n",
    "        width = self.p_widths[pos_id] if pos_id in self.p_widths else get_plot_width(pos_id)\n",
    "        self.p_widths[pos_id] = width\n",
    "        \n",
    "        # Draw plot\n",
    "        st_plot(pp_desc,\n",
    "                width=width, translate=self.tf,\n",
    "                full_df=self.df,data_meta=self.meta,**kwargs)\n",
    "        \n",
    "    def filter_ui(self, dims, detailed=False, raw=False):\n",
    "        return filter_ui(self.df, self.meta, dims=dims, detailed=detailed, raw=raw, translate=self.tf)\n",
    "    \n",
    "    def facet_ui(self, dims, two=False, raw=False):\n",
    "        return facet_ui(dims, two=two, raw=raw, translate=self.tf)\n",
    "\n",
    "    def page(self, name, **kwargs):\n",
    "        def decorator(pfunc):\n",
    "            groups = vod(kwargs,'groups')\n",
    "            if (groups is None or # Page is available to all\n",
    "                vod(self.user,'group')=='admin' or # Admin sees all\n",
    "                vod(self.user,'group','guests') in groups): # group is whitelisted\n",
    "                self.pages.append( (name,pfunc,kwargs) )\n",
    "        return decorator\n",
    "\n",
    "    def build(self):    \n",
    "        # If login failed and is required, don't go any further\n",
    "        if not self.public and not st.session_state[\"authentication_status\"]: return\n",
    "    \n",
    "        # Add user settings page if logged in\n",
    "        if self.user:  self.pages.append( ('Settings',user_settings_page,{'icon': 'sliders'}) )\n",
    "        \n",
    "        # Add admin page for admins\n",
    "        if vod(self.user,'group')=='admin':  self.pages.append( ('Administration', admin_page,{'icon': 'terminal'}) )\n",
    "        \n",
    "        # Draw the menu listing pages\n",
    "        pnames = [t[0] for t in self.pages]\n",
    "        with st.sidebar:\n",
    "            \n",
    "            if self.user:\n",
    "                self.sb_info.info(self.tf('Logged in as **%s**') % self.user[\"name\"])\n",
    "                self.uam.auth.logout(self.tf('Log out'), 'sidebar')\n",
    "            \n",
    "            t_pnames = [ self.tf(pn) for pn in pnames]\n",
    "            menu_choice = option_menu(\"Pages\",\n",
    "                t_pnames,\n",
    "                icons=[vod(t[2],'icon') for t in self.pages],\n",
    "                styles={\n",
    "                    \"container\": {\"padding\": \"5!important\"}, #, \"background-color\": \"#fafafa\"},\n",
    "                    #\"icon\": {\"color\": \"red\", \"font-size\": \"15px\"},\n",
    "                    \"nav-link\": {\"font-size\": \"12px\", \"text-align\": \"left\", \"margin\":\"0px\", \"--hover-color\": \"#eee\"},\n",
    "                    \"nav-link-selected\": {\"background-color\": \"#red\"},\n",
    "                    \"menu-title\": {\"display\":\"none\"}\n",
    "                })\n",
    "            \n",
    "        # Find the page\n",
    "        pname, pfunc, meta = self.pages[t_pnames.index(menu_choice)]\n",
    "        \n",
    "        # Load data\n",
    "        self.data_source = vod(meta,'data_source',self.data_source)\n",
    "        with st.spinner(self.tf(\"Loading data...\")):\n",
    "            self.df, self.meta = read_annotated_data_cached(alias_file(self.data_source,self.filemap))\n",
    "        \n",
    "        # Render the chosen page\n",
    "        st.title(pname)\n",
    "        pfunc(**clean_kwargs(pfunc,{'sdb':self}))\n",
    "        \n",
    "    # Add enter and exit so it can be used as a context\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    # Render everything once we exit the with block\n",
    "    def __exit__(self, exc_type, exc_value, exc_tb):\n",
    "        self.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stauth.Hasher(['kalasaba']).generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class UserAuthenticationManager():\n",
    "    \n",
    "    def __init__(self,auth_conf_file,groups,s3_fs,info,logger,translate_func):\n",
    "        self.groups, self.s3fs, self.info  = groups, s3_fs, info\n",
    "        \n",
    "        config = load_json_cached(auth_conf_file, _s3_fs = self.s3fs)\n",
    "        self.conf, self.conf_file = config, auth_conf_file\n",
    "        self.auth = stauth.Authenticate(\n",
    "            config['credentials'],\n",
    "            config['cookie']['name'],\n",
    "            config['cookie']['key'],\n",
    "            config['cookie']['expiry_days'],\n",
    "            config['preauthorized']\n",
    "        )\n",
    "        self.users = config['credentials']['usernames']\n",
    "        self.user = {} # Filled on login\n",
    "        self.log_event = logger\n",
    "        self.tf = translate_func\n",
    "        \n",
    "        # Mark that we should log the next login\n",
    "        if 'log_event' not in st.session_state: st.session_state['log_event'] = True\n",
    "                          \n",
    "    def require_admin(self):\n",
    "        if not self.admin: raise Exception(\"This action requires administrator privileges\")\n",
    "    \n",
    "    def load_uncached_conf(self):\n",
    "        self.conf = load_json(self.conf_file, _s3_fs = self.s3fs)\n",
    "        self.users = self.conf['credentials']['usernames']\n",
    "    \n",
    "    def login_screen(self):\n",
    "        _, _, username = self.auth.login(self.tf('Log in'), 'main')\n",
    "        \n",
    "        if st.session_state[\"authentication_status\"] is False:\n",
    "            st.error(self.tf('Username/password is incorrect'))\n",
    "            self.log_event('login-fail', username=username)\n",
    "        if st.session_state[\"authentication_status\"] is None:\n",
    "            st.warning(self.tf('Please enter your username and password'))\n",
    "            st.session_state['log_event'] = True \n",
    "        elif st.session_state[\"authentication_status\"]:\n",
    "            self.user = {'name': st.session_state['name'], \n",
    "                         'username': username,\n",
    "                         **self.users[username] }\n",
    "            \n",
    "            #check if signing in has been logged - if not, log it and flip the flag\n",
    "            if st.session_state['log_event']:\n",
    "                self.log_event('login-success')\n",
    "                st.session_state['log_event'] = False\n",
    "        \n",
    "        self.admin = (vod(self.user,'group') == 'admin')\n",
    "        \n",
    "    def update_conf(self):\n",
    "        with open_fn(self.conf_file,'w',s3_fs=self.s3fs) as jf:\n",
    "            json.dump(self.conf,jf)\n",
    "        st.rerun() # Force a rerun to reload the new file\n",
    "            \n",
    "    def add_user(self, username, password, user_data):\n",
    "        self.require_admin()\n",
    "        if username not in self.users:\n",
    "            user_data['password'] = stauth.Hasher([password]).generate()[0]\n",
    "            self.users[username] = user_data\n",
    "            self.info.success(f'User {username} successfully added.')\n",
    "            self.log_event(f'add-user: {username}')\n",
    "            self.update_conf()\n",
    "            return True\n",
    "        else:\n",
    "            self.info.error(f'User **{username}** already exists.')\n",
    "            return False\n",
    "        \n",
    "    def change_user(self, username, user_data):\n",
    "        \n",
    "        # Change username\n",
    "        if 'username' in user_data and username != user_data['username']:\n",
    "            self.users[user_data['username']] = self.users[username]\n",
    "            del self.users[username]\n",
    "            username = user_data['username']\n",
    "            del user_data['username']\n",
    "        \n",
    "        # Handle password change\n",
    "        if vod(user_data,'password'):\n",
    "            user_data['password'] = stauth.Hasher([user_data['password']]).generate()[0]\n",
    "        else: del user_data['password']\n",
    "        \n",
    "        # Update everything else\n",
    "        self.users[username].update(user_data)\n",
    "        self.log_event(f'change-user: {username}')\n",
    "        self.info.success(f'User **{username}** changed.')\n",
    "        self.update_conf()\n",
    "        \n",
    "    def delete_user(self, username): \n",
    "        self.require_admin()\n",
    "        del self.users[username]\n",
    "        self.info.warning(f'User **{username}** deleted.')\n",
    "        print(f\"Delete user {username}\")\n",
    "        self.log_event(f'delete-user: {username}')\n",
    "        self.update_conf()\n",
    "\n",
    "    def list_users(self):\n",
    "        self.require_admin()\n",
    "        return [ censor_dict({'username': k, **v},['password']) for k,v in self.users.items() ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Admin pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti \n",
    "\n",
    "# Password reset\n",
    "def user_settings_page(sdb):\n",
    "    if not sdb.user: return\n",
    "    try:\n",
    "        if sdb.uam.auth.reset_password(st.session_state[\"username\"], sdb.tf('Reset password')):\n",
    "            sdb.uam.update_conf()\n",
    "            st.success(sdb.tf('Password modified successfully'))\n",
    "    except Exception as e:\n",
    "        st.error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "# Helper function to highlight log rows\n",
    "def highlight_cells(val):\n",
    "    if 'fail' in val:\n",
    "        color = 'red'\n",
    "    #elif 'add' in val:\n",
    "    elif any(s in val for s in ['delete', 'add', 'change']):\n",
    "        color = 'blue'\n",
    "    elif 'success' in val:\n",
    "        color='green'\n",
    "    else:\n",
    "        color = ''\n",
    "    return 'color: {}'.format(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti \n",
    "\n",
    "# Admin page to manage users\n",
    "\n",
    "def admin_page(sdb):\n",
    "    sdb.uam.require_admin()\n",
    "    sdb.uam.load_uncached_conf() # so all admin updates would immediately be visible\n",
    "    \n",
    "    menu_choice = option_menu(None,[ 'Log management', 'List users', 'Add user', 'Change user', 'Delete user' ], \n",
    "                              icons=['card-list','people-fill','person-fill-add','person-lines-fill','person-fill-dash'], orientation='horizontal')\n",
    "    st.write(\" \")\n",
    "\n",
    "    if menu_choice=='Log management':\n",
    "        log_data=pd.read_csv(alias_file(sdb.log_path,sdb.filemap),names=['timestamp','event','username'])\n",
    "        st.dataframe(log_data.sort_index(ascending=False\n",
    "            ).style.applymap(highlight_cells, subset=['event']), width=1200) #use_container_width=True\n",
    "        \n",
    "    elif menu_choice=='List users':\n",
    "        # Read log to get last login:\n",
    "        log_data = pd.read_csv(alias_file(sdb.log_path,sdb.filemap),names=['timestamp','event','username'])\n",
    "        log_data = log_data[log_data['event']=='login-success']\n",
    "        log_data['timestamp'] = pd.to_datetime(log_data['timestamp'])\n",
    "        \n",
    "        # Add last login to users\n",
    "        users = sdb.uam.list_users()\n",
    "        for u in users:\n",
    "            last_login = log_data[log_data['username'] == u['username']].timestamp.max()\n",
    "            if pd.notnull(last_login):\n",
    "                u['last_login'] = last_login.strftime('%d-%b-%Y')\n",
    "                \n",
    "        # Display the data\n",
    "        st.dataframe(users, use_container_width=True)\n",
    "\n",
    "    elif menu_choice=='Add user':\n",
    "        with st.form(\"add_user_form\"):\n",
    "            st.subheader(\"Add user:\")\n",
    "            st.markdown(\"\"\"---\"\"\")\n",
    "            col1,col2 = st.columns((1,2))\n",
    "            user_data = {}\n",
    "            with col1:\n",
    "                user_data['group'] = st.radio(\"Group:\", sdb.uam.groups)\n",
    "            with col2:\n",
    "                username = st.text_input(\"Username:\")\n",
    "                password = st.text_input(\"Password:\", type='password')\n",
    "                user_data['name'] = st.text_input(\"Name:\")\n",
    "                st.markdown(\"\"\"---\"\"\")\n",
    "                user_data['email'] = st.text_input(\"E-mail:\")\n",
    "            st.markdown(\"\"\"---\"\"\")\n",
    "            submitted = st.form_submit_button(\"Submit\")\n",
    "            if submitted:\n",
    "                if not '' in [username, password, user_data['email']]:\n",
    "                    sdb.uam.add_user(username, password, user_data)\n",
    "                else:\n",
    "                    sdb.info.error('Must specify username, password and email.')\n",
    "\n",
    "    elif menu_choice=='Change user':\n",
    "        username=st.selectbox('Edit user', list(sdb.uam.users.keys()))\n",
    "        \n",
    "        user_data = sdb.uam.users[username].copy()\n",
    "        #st.write(user_data)\n",
    "        group_index = sdb.uam.groups.index(user_data['group'])\n",
    "\n",
    "        with st.form(\"edit_user_form\"):\n",
    "            st.subheader(\"Edit user data:\")\n",
    "            st.markdown(\"\"\"---\"\"\")\n",
    "            col1,col2 = st.columns((1,2))\n",
    "            with col1:\n",
    "                user_data['username'] = st.text_input(\"Username:\", value=username, disabled=True)\n",
    "                user_data['group'] = st.radio(\"Group:\", sdb.uam.groups, index=group_index) #, disabled=True)\n",
    "            with col2:\n",
    "                #new_user = st.text_input(\"Kasutaja:\", value=username, disabled=True)\n",
    "                user_data['name'] = st.text_input(\"Name:\", value=user_data['name'])\n",
    "                user_data['password'] = st.text_input(\"Password:\", type='password')\n",
    "                st.markdown(\"\"\"---\"\"\")\n",
    "                user_data['email'] = st.text_input(\"E-mail:\", value=user_data['email'])\n",
    "            st.markdown(\"\"\"---\"\"\")\n",
    "            submitted = st.form_submit_button(\"Submit\")\n",
    "            if submitted:\n",
    "                sdb.uam.change_user(username,user_data)\n",
    "                \n",
    "    elif menu_choice=='Delete user':\n",
    "        with st.form(\"delete_user_form\"):\n",
    "            st.subheader('Delete user:')\n",
    "            username = st.selectbox('Select username:', list(sdb.uam.users.keys()))\n",
    "            check = st.checkbox('Deletion is FINAL and cannot be undone!')\n",
    "            st.markdown(\"\"\"___\"\"\")\n",
    "            submitted = st.form_submit_button(\"Delete\")\n",
    "            if submitted:\n",
    "                if not check:\n",
    "                    sdb.info.warning(f'Tick the checkbox in order to delete user **{username}**.')\n",
    "                elif username == sdb.user['username']:\n",
    "                    sdb.info.error('Cannot delete the current user.')\n",
    "                else:\n",
    "                    sdb.uam.delete_user(username)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippets copied over from dashboard.py to be re-purposed here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - copy the timestamp logic here over to our list_users\n",
    "def list_users():\n",
    "    with fs.open(user_file, 'r') as f:\n",
    "        data=f.read()\n",
    "        u_dict=json.loads(data)\n",
    "        f.close()\n",
    "\n",
    "    log_data=pd.read_csv(log_file)\n",
    "    log_data['timestamp']= pd.to_datetime(log_data['timestamp'],\n",
    "        utc=True, infer_datetime_format=True)\n",
    "\n",
    "    login_list = []\n",
    "    name_list = []\n",
    "    email_list = []\n",
    "    group_list = []\n",
    "\n",
    "    for u in u_dict.keys():\n",
    "        last_login=log_data[log_data.user == u].timestamp.max()\n",
    "        if pd.notnull(last_login):\n",
    "            last_login=last_login.strftime('%d-%b-%Y')\n",
    "        login_list.append(last_login)\n",
    "        name_list.append(u_dict[u]['name'])\n",
    "        email_list.append(u_dict[u]['e-mail'])\n",
    "        group_list.append(u_dict[u]['group'])\n",
    "\n",
    "    d = {\n",
    "        'user': u_dict.keys(),\n",
    "        'name': name_list,\n",
    "        'group': group_list,\n",
    "        #'e-mail': email_list,\n",
    "        'last login': login_list\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other shared parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# This is a horrible workaround to get faceting to work with altair geoplots that do not play well with streamlit\n",
    "# See https://github.com/altair-viz/altair/issues/2369 -> https://github.com/vega/vega-lite/issues/3729\n",
    "\n",
    "# Draw a matrix of plots using separate plots and st columns\n",
    "def draw_plot_matrix(pmat,matrix_form = False):\n",
    "    if not pmat: return # Do nothing if get None passed to it\n",
    "    if not matrix_form: pmat = [[pmat]]\n",
    "    cols = st.columns(len(pmat[0]))\n",
    "    for j,c in enumerate(cols):\n",
    "        for i, row in enumerate(pmat):\n",
    "            c.altair_chart(pmat[i][j])\n",
    "\n",
    "# Draw the plot described by pp_desc \n",
    "def st_plot(pp_desc,**kwargs):\n",
    "    matrix_form = (pp_desc['plot'] == 'geoplot')\n",
    "    plots = e2e_plot(pp_desc, return_matrix_of_plots=matrix_form, **kwargs)\n",
    "    draw_plot_matrix(plots, matrix_form=matrix_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def facet_ui(dims, two=False, raw=False, translate=None):\n",
    "    \n",
    "    # Set up translation\n",
    "    tf = translate if translate else (lambda s: s)\n",
    "    tdims = [ tf(d) for d in dims ]\n",
    "    r_map = dict(zip(tdims,dims))\n",
    "    \n",
    "    none = tf('None')\n",
    "    stc = st.sidebar if not raw else st\n",
    "    facet_dim = stc.selectbox(tf('Facet:'), [none] + tdims)\n",
    "    fcols = [facet_dim] if facet_dim != none else []\n",
    "    if two and facet_dim != none:\n",
    "        second_dim = stc.selectbox(tf('Facet 2:'), [none] + tdims)\n",
    "        if second_dim not in [none,facet_dim]:  fcols = [facet_dim, second_dim]\n",
    "        \n",
    "    return [ r_map[d] for d in fcols ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "# Function that creates reset functions for multiselects in filter\n",
    "def ms_reset(cn, all_vals):\n",
    "    def reset_ms():\n",
    "        st.session_state[f\"{cn}_multiselect\"] = all_vals\n",
    "    return reset_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# User interface that outputs a filter for the pp_desc\n",
    "def filter_ui(data, dmeta=None, dims=None, detailed=False, raw=False, translate=None):\n",
    "    \n",
    "    tf = translate if translate else (lambda s: s)\n",
    "    \n",
    "    if dims is None:\n",
    "        dims = [c for c in data.columns if c not in ['draw', 'weight', 'training_subsample'] ]  \n",
    "    \n",
    "    if dmeta is not None:\n",
    "        dims = list_aliases(dims, group_columns_dict(dmeta)) # Replace aliases like 'demographics'\n",
    "        c_meta = extract_column_meta(dmeta) # mainly for groups defined in meta\n",
    "    else: c_meta = defaultdict(lambda: {})\n",
    "    \n",
    "    f_info = st.sidebar.empty() if not raw else st.empty()\n",
    "    \n",
    "    stc = st.sidebar.expander(tf('Filters')) if not raw else st\n",
    "    \n",
    "    # Different selector for different category types\n",
    "    # Also - make sure filter is clean and only applies when it is changed from the default 'all' value\n",
    "    # This has considerable speed and efficiency implications\n",
    "    filters = {}\n",
    "    for cn in dims:\n",
    "        col = data[cn]\n",
    "        if col.dtype.name=='category':\n",
    "            if len(col.dtype.categories)==1: continue\n",
    "            \n",
    "            # Do some prep for translations\n",
    "            r_map = dict(zip([tf(c) for c in col.dtype.categories],col.dtype.categories))\n",
    "            all_vals = list(r_map.keys()) # translated categories\n",
    "            grp_names = vod(c_meta[cn],'groups',{}).keys()\n",
    "            r_map.update(dict(zip([tf(c) for c in grp_names],grp_names)))\n",
    "            \n",
    "        if detailed and col.dtype.name=='category':\n",
    "            filters[cn] = stc.multiselect(tf(cn), all_vals, all_vals, key=f\"{cn}_multiselect\")\n",
    "            if set(filters[cn]) == set(all_vals): del filters[cn]\n",
    "            else: \n",
    "                stc.button(tf(\"Reset\"),key=f\"{cn}_reset\",on_click=ms_reset(cn,all_vals))\n",
    "                filters[cn] = [ r_map[c] for c in filters[cn] ]\n",
    "        elif col.dtype.name=='category' and not col.dtype.ordered:\n",
    "            filters[cn] = stc.selectbox(cn,\n",
    "                [tf('All')] + [gt for gt,g in r_map.items() if g in grp_names] + all_vals)\n",
    "            if filters[cn] == tf('All'): del filters[cn]\n",
    "            else: filters[cn] = r_map[filters[cn]]\n",
    "        elif col.dtype.name=='category':\n",
    "            filters[cn] = stc.select_slider(cn,all_vals,value=(all_vals[0],all_vals[-1]))\n",
    "            if filters[cn] == (all_vals[0],all_vals[-1]): del filters[cn]\n",
    "            else: filters[cn] = (r_map[filters[cn][0]],r_map[filters[cn][1]])\n",
    "        elif is_numeric_dtype(col) and col.dtype!='bool':\n",
    "            mima = (col.min(),col.max())\n",
    "            if mima[0]==mima[1]: continue\n",
    "            filters[cn] = stc.slider(cn,*mima,value=mima)\n",
    "            if filters[cn] == mima: del filters[cn]\n",
    "            \n",
    "    if filters: f_info.warning(tf('⚠️ Filters active ⚠️'))\n",
    "            \n",
    "    return filters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Use dict here as dicts are ordered as of Python 3.7 and preserving order groups things together better\n",
    "\n",
    "def translate_with_dict(d):\n",
    "    return (lambda s: d[s] if isinstance(s,str) and s in d and d[s] is not None else s)\n",
    "\n",
    "def log_missing_translations(tf, nonchanged_dict):\n",
    "    def ntf(s):\n",
    "        ns = tf(s)\n",
    "        if ns==s: nonchanged_dict[s]=None\n",
    "        return ns\n",
    "    return ntf\n",
    "\n",
    "def clean_missing_translations(nonchanged_dict, tdict={}):\n",
    "    # Filter out numbers that come in from data sometimes\n",
    "    return { s:v for s,v in nonchanged_dict.items() if s not in tdict and isinstance(s,str) and not re.fullmatch('[\\.\\d]+',s) }\n",
    "\n",
    "def add_missing_to_dict(missing_dict, tdict):\n",
    "    return {**tdict, **{ s:s for s in missing_dict}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup guide\n",
    "- User conf\n",
    "  - cookie key matters. generate a decent one random\n",
    "- Logfile - make sure to touch a local one so local logs don't pollute the deploy\n",
    "- Files: if deploy.json targets missing, notify. If files not present in s3, copy over. Add flag to have them updated\n",
    "- Translations: keep in repo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
